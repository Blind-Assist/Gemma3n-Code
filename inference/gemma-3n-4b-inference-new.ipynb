{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "605cabce-e404-4892-8883-f507162dc779",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os, re\n",
    "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
    "    !pip install unsloth\n",
    "else:\n",
    "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
    "    import torch; v = re.match(r\"[0-9\\.]{3,}\", str(torch.__version__)).group(0)\n",
    "    xformers = \"xformers==\" + (\"0.0.32.post2\" if v == \"2.8.0\" else \"0.0.29.post3\")\n",
    "    !pip install --no-deps bitsandbytes accelerate {xformers} peft trl triton cut_cross_entropy unsloth_zoo\n",
    "    !pip install sentencepiece protobuf \"datasets>=3.4.1,<4.0.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
    "    !pip install --no-deps unsloth\n",
    "!pip install transformers==4.55.4\n",
    "!pip install timm\n",
    "import torch; torch._dynamo.config.recompile_limit = 64;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aedf757-aba4-4399-a8c2-87d70ca5e661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.12.6: Fast Gemma3N patching. Transformers: 4.55.4.\n",
      "   \\\\   /|    NVIDIA A40. Num GPUs = 1. Max memory: 44.339 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 8.6. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.33.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ec6341214e4e87abd72dc83d0eac6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebf0cd42cc5747e4b40b0710719cf42d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/210 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "132341e13a7d4e39b2c6d75811a5a3e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processor_config.json:   0%|          | 0.00/98.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6572dc5e95d1454683b86a7a28e76bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ba692aadd744a0d9ac147deb41bdbab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a759db9d92547cc9cb730000f7e6fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e565b7bca7c4c9d833fecdb32048dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.70M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d9a279fa0a4140b5cc6f3fa915e79f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f081ca102744179964eb8ffcc746a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/777 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from unsloth import FastModel\n",
    "import torch\n",
    "\n",
    "fourbit_models = [\n",
    "    # 4bit dynamic quants for superior accuracy and low memory use\n",
    "    \"unsloth/gemma-3n-E4B-it-unsloth-bnb-4bit\",\n",
    "    \"unsloth/gemma-3n-E2B-it-unsloth-bnb-4bit\",\n",
    "    # Pretrained models\n",
    "    \"unsloth/gemma-3n-E4B-unsloth-bnb-4bit\",\n",
    "    \"unsloth/gemma-3n-E2B-unsloth-bnb-4bit\",\n",
    "\n",
    "    # Other Gemma 3 quants\n",
    "    \"unsloth/gemma-3-1b-it-unsloth-bnb-4bit\",\n",
    "    \"unsloth/gemma-3-4b-it-unsloth-bnb-4bit\",\n",
    "    \"unsloth/gemma-3-12b-it-unsloth-bnb-4bit\",\n",
    "    \"unsloth/gemma-3-27b-it-unsloth-bnb-4bit\",\n",
    "] # More models at https://huggingface.co/unsloth\n",
    "\n",
    "model, tokenizer = FastModel.from_pretrained(\n",
    "    model_name = \"unsloth/gemma-3n-E4B-it\",\n",
    "    dtype = None, # None for auto detection\n",
    "    max_seq_length = 1024, # Choose any for long context!\n",
    "    load_in_4bit = True,  # 4 bit quantization to reduce memory\n",
    "    full_finetuning = False, # [NEW!] We have full finetuning now!\n",
    "    # token = \"hf_...\", # use one if using gated models\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de998d19-620c-409b-a54f-9bdbcf5570d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextStreamer\n",
    "# Helper function for inference\n",
    "def do_gemma_3n_inference(messages, max_new_tokens = 128):\n",
    "    # _ = model.generate(\n",
    "    #     **tokenizer.apply_chat_template(\n",
    "    #         messages,\n",
    "    #         add_generation_prompt = True, # Must add for generation\n",
    "    #         tokenize = True,\n",
    "    #         return_dict = True,\n",
    "    #         return_tensors = \"pt\",\n",
    "    #     ).to(\"cuda\"),\n",
    "    #     max_new_tokens = max_new_tokens,\n",
    "    #     temperature = 1.0, top_p = 0.95, top_k = 64,\n",
    "    #     streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
    "    #)\n",
    "    # 1. Prepare inputs\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt = True,\n",
    "        tokenize = True,\n",
    "        return_dict = True,\n",
    "        return_tensors = \"pt\",\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    # 2. Generate\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens = max_new_tokens,\n",
    "        temperature = 0.1, # Lower temperature is better for navigation (more factual)\n",
    "        do_sample = True,\n",
    "        # Keep the streamer so you can still watch it work in the notebook\n",
    "        streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
    "    )\n",
    "\n",
    "    # 3. Decode only the NEW tokens (the answer)\n",
    "    input_length = inputs.input_ids.shape[1]\n",
    "    new_tokens = outputs[0][input_length:]\n",
    "    response_text = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2acbe0d-e590-4498-a3b2-9b69475469d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Collecting numpy<2.3.0,>=2 (from opencv-python)\n",
      "  Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (67.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m205.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m120.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, opencv-python\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.3\n",
      "    Uninstalling numpy-1.26.3:\n",
      "      Successfully uninstalled numpy-1.26.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "trl 0.24.0 requires transformers>=4.56.1, but you have transformers 4.55.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-2.2.6 opencv-python-4.12.0.88\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36c1d9b0-e6ec-4192-85e7-aa75349d932c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "def extract_frames_from_path(video_path, num_frames=10):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video file.\")\n",
    "        return []\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Calculate the step size (logic from your first source)\n",
    "    step = total_frames // num_frames\n",
    "    frames = []\n",
    "\n",
    "    for i in range(num_frames):\n",
    "        frame_idx = i * step\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Convert BGR (OpenCV) to RGB (PIL) without rotation\n",
    "        img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        frames.append(img)\n",
    "\n",
    "    cap.release()\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99cb478a-61ef-465a-b064-ca9e2f9c9f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15 videos. Starting processing...\n",
      "Processing: 20240918-youtube_short_83bc88612ff6a00628af923c9ff461cb_2m9s.mp4...\n",
      "## Safety Alert:\n",
      "\n",
      "**Immediate High-Risk Obstruction:** There is a glass railing located at approximately 11:00 on the 12-hour clock face. Please be mindful of this railing as you navigate the walkway. \n",
      "\n",
      "**Reasoning:** The railing is a potential tripping hazard if not detected. \n",
      "\n",
      "**Additional Notes:** The walkway appears to be busy with people, so maintaining awareness of your surroundings is important. \n",
      "\n",
      "\n",
      "\n",
      "<end_of_turn>\n",
      "Processing: 20240918-youtube_short_b2393a2b8d5fe9bc63504236205ceb98_13s.mp4...\n",
      "## Safety Alert:\n",
      "\n",
      "**High-risk obstruction:** A metal railing is located directly in your path at approximately the 11:00 position. Please be cautious as you approach this area. \n",
      "\n",
      "**Additional observations:** There are people seated at tables outside several establishments along the street, and some parked bicycles. Be mindful of these individuals and objects as you navigate the area.<end_of_turn>\n",
      "Processing: 20240918-youtube_short_b47bfc6eff24bcacbc44e6f85504989b_34s.mp4...\n",
      "## Safety Alert:\n",
      "\n",
      "**Immediate High-Risk Obstruction:** A person is walking towards you from the right side of the frame, approaching from the 6 o'clock position. \n",
      "\n",
      "**Actionable Safety Alert:** Be aware of the person approaching from your right and adjust your path accordingly to avoid a collision. \n",
      "\n",
      "**Note:** The video shows multiple people walking on the sidewalk, but the person approaching from the right is the most immediate and high-risk obstruction. \n",
      "\n",
      "\n",
      "\n",
      "<end_of_turn>\n",
      "Processing: 20240918-youtube_short_081e0a96bac802b988a1db9df310ddd1_1min03s.mp4...\n",
      "## Safety Alert:\n",
      "\n",
      "**High-risk obstruction detected at 11:00.** A scooter is moving towards your right in the lane adjacent to the sidewalk. Please be aware of its movement. \n",
      "\n",
      "**Note:** This alert is based on the visual information provided in the video. It is recommended to always exercise caution when navigating roads and be aware of your surroundings.<end_of_turn>\n",
      "Processing: 20240918-youtube_short_f6ddaedf7aae1b02a56dee04381de8f7_3min02s.mp4...\n",
      "## Safety Alert:\n",
      "\n",
      "**Immediate High-Risk Obstruction:** A motorcycle is approaching from the left, positioned approximately at the 11:00 position in your forward view. \n",
      "\n",
      "**Actionable Safety Alert:** Be aware of approaching motorcycles on your left.<end_of_turn>\n",
      "Processing: 20240918-youtube_short_fe880bc6cb4798233f2a42ad07167abe_2min29s.mp4...\n",
      "## Safety Alert:\n",
      "\n",
      "**Immediate High-Risk Obstruction:** A person pushing a stroller is approaching from behind on the right side of the walkway. \n",
      "\n",
      "**Location:** Approximately 3:00. \n",
      "\n",
      "**Action:** Please be aware of the person and stroller approaching from behind and maintain a safe distance. \n",
      "\n",
      "\n",
      "\n",
      "<end_of_turn>\n",
      "Processing: 20240918-youtube_short_a05bdd8de0648caa248f14cb47fe4c5b_3m50s.mp4...\n",
      "## Safety Alert:\n",
      "\n",
      "**High-risk obstruction detected at 11:00.** There are people walking on the sidewalk directly in your path. Please be cautious and aware of your surroundings. \n",
      "\n",
      "**Note:** This analysis is based on the provided video and may not capture all potential hazards. It is always recommended to exercise caution when navigating in crowded areas.<end_of_turn>\n",
      "Processing: 20240918-youtube_short_a2790d9962f7e72ba445e395d9b1dc19_4min48s.mp4...\n",
      "## Safety Alert:\n",
      "\n",
      "**High-risk obstruction detected at 11:00.** A vehicle is parked very close to the right side of the road, potentially limiting space for safe passage. Please be cautious when navigating this area. \n",
      "\n",
      "**Note:** This analysis is based on the visual information provided in the video. Other potential hazards may exist that are not visible in the frame. \n",
      "\n",
      "\n",
      "\n",
      "<end_of_turn>\n",
      "Processing: 20240918-youtube_short_b2393a2b8d5fe9bc63504236205ceb98_1min28s.mp4...\n",
      "## Safety Alert:\n",
      "\n",
      "**High-risk obstruction detected at approximately 11:00.** There is a low-hanging orange awning extending from the building on the right side of the alleyway. It is positioned at a height that could pose a hazard if you are not paying attention. Please be mindful of this obstruction as you navigate the alley. \n",
      "\n",
      "**Note:** This analysis is based on the provided video and may not capture all potential hazards. It is always recommended to exercise caution when navigating unfamiliar environments.<end_of_turn>\n",
      "Processing: 20240918-youtube_short_2711f140bac74f83aa0a56272ec7f6de_3s.mp4...\n",
      "## Safety Alert:\n",
      "\n",
      "**Immediate High-Risk Obstruction:** A pigeon is walking on the sidewalk directly in your path. \n",
      "\n",
      "**Location:** 3:00\n",
      "\n",
      "**Action:** Please be mindful of the pigeon and adjust your walking path accordingly to avoid collision. \n",
      "\n",
      "\n",
      "\n",
      "<end_of_turn>\n",
      "Processing: 20240918-youtube_short_1cb8f8832a143fde640ff92d7c656280_4m28s.mp4...\n",
      "## Safety Alert:\n",
      "\n",
      "**High-risk obstruction:** A low-hanging electrical cord is present on the sidewalk at approximately 11:00. \n",
      "\n",
      "**Location:** Sidewalk, near the left side of the frame. \n",
      "\n",
      "**Action:** Please be cautious of the low-hanging cord as it could pose a tripping hazard. \n",
      "\n",
      "\n",
      "\n",
      "<end_of_turn>\n",
      "Processing: 20240918-youtube_short_1aec7c3e80c13cbb75f75f72333148bf_2min24s.mp4...\n",
      "## Analysis of Video for Visually Impaired User\n",
      "\n",
      "**Immediate, High-Risk Obstructions:**\n",
      "\n",
      "* **0:00 - 0:05:** A person is walking on the sidewalk to the left, approximately at the 11:00 position.\n",
      "* **0:05 - 0:10:** Several people are walking on the sidewalk to the left, closer to the 10:00 position.\n",
      "* **0:10 - 0:15:** A person is walking on the sidewalk to the left, near the 11:00 position.\n",
      "* **0:15 - 0:20:** A person is walking on the sidewalk to the left, closer to the 10:00 position.\n",
      "* **0:20 - 0:25:** A person is walking on the sidewalk to the left, near the 11:00 position.\n",
      "* **0:25 - 0:30:** A person is walking on the sidewalk to the left, closer to the 10:00 position.\n",
      "* **0:30 - 0:35:** A person is walking on the sidewalk to\n",
      "Processing: 20240918-youtube_short_11bc0f3b2d7f68e62f5d61a10d2f8897_4min03s.mp4...\n",
      "Based on the video, there are no immediate, high-risk obstructions visible in the user's forward perspective. The surface appears to be a smooth, flat wall. \n",
      "\n",
      "**Safety Alert:** The wall appears to be smooth and clear of any immediate obstacles.<end_of_turn>\n",
      "Processing: 20240918-youtube_short_af4db50cb1cbddf708fa2cdd2e5c1053_3m22s.mp4...\n",
      "## Safety Alert:\n",
      "\n",
      "**High-risk obstruction detected at 11:00.** There are numerous shoes displayed on the floor and shelves directly in front of the store, posing a tripping hazard. Please proceed with caution.<end_of_turn>\n",
      "Processing: 20240914_1abe4d6f616ccb2d8e15049136e1656d_4m28s.mp4...\n",
      "## Safety Alert:\n",
      "\n",
      "**High-risk obstruction detected at 11:00.** A green barrier with orange and black stripes is directly to your right, potentially narrowing the available path. Please be mindful of its presence as you navigate. \n",
      "\n",
      "**Additional observations:**\n",
      "\n",
      "* There are trees and poles lining the sidewalk on your left.\n",
      "* Vehicles are present on the road to your left. \n",
      "* Pedestrians and cyclists are also present on the sidewalk. \n",
      "\n",
      "**Note:** This analysis is based on the provided video and may not capture all potential hazards. It is always recommended to remain vigilant and aware of your surroundings.<end_of_turn>\n",
      "\n",
      "Success! Saved results to gemma3n-4b_inference_results.csv\n"
     ]
    }
   ],
   "source": [
    "video_folder = \"videos\"  #folder name\n",
    "output_csv = \"gemma3n-4b_inference_results.csv\"\n",
    "results = []\n",
    "\n",
    "# Get list of all video files\n",
    "video_files = [f for f in Path(video_folder).iterdir() if f.suffix in ['.mp4', '.mov', '.avi']]\n",
    "\n",
    "print(f\"Found {len(video_files)} videos. Starting processing...\")\n",
    "\n",
    "for video_path in video_files:\n",
    "    print(f\"Processing: {video_path.name}...\")\n",
    "    \n",
    "    # 1. Extract the \"Frame Thing\" (10 snapshots)\n",
    "    video_frames = extract_frames_from_path(video_path, num_frames=10)\n",
    "    \n",
    "    if not video_frames:\n",
    "        continue\n",
    "\n",
    "    # 2. Build the message\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                *[{\"type\": \"image\", \"image\": img} for img in video_frames],\n",
    "                {\"type\": \"text\", \"text\": \"You are an assistive navigation system for a visually impaired user. Analyze the provided video from the user's forward perspective. Identify all the immediate, high-risk obstructions. State the obstruction's location using the 12-hour clock face. Process the provided video generate a single, actionable safety alert.\"}\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # 3. Inference\n",
    "    try:\n",
    "        response = do_gemma_3n_inference(messages, max_new_tokens=256)\n",
    "        results.append([video_path.name, response])\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {video_path.name}: {e}\")\n",
    "\n",
    "# --- Save to CSV ---\n",
    "with open(output_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"video_name\", \"model_output\"])\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(f\"\\nSuccess! Saved results to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7131ee8b-6843-4aa4-9fa5-dd5c2d56a59c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
